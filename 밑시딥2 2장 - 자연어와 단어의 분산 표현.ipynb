{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![밑시딥2 교재](http://www.hanbit.co.kr/data/books/B8950212853_l.jpg)\n",
    "\n",
    "> 작성자 : [Minsuk Sung](https://github.com/mssung94)  \n",
    "> 연락처 : mssung94@gmail.com  \n",
    "> GitHub : https://github.com/mssung94\n",
    "\n",
    "> 본 내용은 **대학생 빅데이터 동아리 `BOAZ`의 딥러닝 스터디 자료**입니다. **상업적인 목적으로 사용하는 것은 절대로 금합니다.**\n",
    "\n",
    "> 모든 내용은 `밑바닥부터 시작하는 딥러닝2(Deep Learning from Scratch 2),한빛미디어`을 참고하여 만들어졌으며, 책의 내용에 대한 모든 저작권은 `한빛미디어`에게 있음을 미리 밝힙니다. 또한 여기에 사용된 코드의 대부분은 한빛미디어에서 제공해준 GitHub을 바탕으로 재구성하였습니다.\n",
    "\n",
    "한빛미디어 홈페이지 : http://www.hanbit.co.kr/store/books/look.php?p_code=B8950212853  \n",
    "밑바닥부터 시작하는 딥러닝 GitHub : https://github.com/WegraLee/deep-learning-from-scratch-2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>2장 자연어와 단어의 분산 표현<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#자연어-처리란?-(p78)\" data-toc-modified-id=\"자연어-처리란?-(p78)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>자연어 처리란? (p78)</a></span><ul class=\"toc-item\"><li><span><a href=\"#단어의-의미\" data-toc-modified-id=\"단어의-의미-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>단어의 의미</a></span></li></ul></li><li><span><a href=\"#시소러스-(p79)\" data-toc-modified-id=\"시소러스-(p79)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>시소러스 (p79)</a></span><ul class=\"toc-item\"><li><span><a href=\"#WordNet\" data-toc-modified-id=\"WordNet-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>WordNet</a></span></li><li><span><a href=\"#시소러스의-문제점\" data-toc-modified-id=\"시소러스의-문제점-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>시소러스의 문제점</a></span></li></ul></li><li><span><a href=\"#통계-기반-기법-(p82)\" data-toc-modified-id=\"통계-기반-기법-(p82)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>통계 기반 기법 (p82)</a></span><ul class=\"toc-item\"><li><span><a href=\"#파이썬으로-말뭉치-전처리하기\" data-toc-modified-id=\"파이썬으로-말뭉치-전처리하기-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>파이썬으로 말뭉치 전처리하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#소문자로-변환하기\" data-toc-modified-id=\"소문자로-변환하기-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>소문자로 변환하기</a></span></li><li><span><a href=\"#마침표-처리하기\" data-toc-modified-id=\"마침표-처리하기-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>마침표 처리하기</a></span></li><li><span><a href=\"#띄어쓰기-단위로-단어-나누기\" data-toc-modified-id=\"띄어쓰기-단위로-단어-나누기-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>띄어쓰기 단위로 단어 나누기</a></span></li><li><span><a href=\"#단어를-ID로,-ID를-단어로\" data-toc-modified-id=\"단어를-ID로,-ID를-단어로-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>단어를 ID로, ID를 단어로</a></span></li><li><span><a href=\"#corpus-만들기\" data-toc-modified-id=\"corpus-만들기-3.1.5\"><span class=\"toc-item-num\">3.1.5&nbsp;&nbsp;</span>corpus 만들기</a></span></li><li><span><a href=\"#1~5단계를-한번에-묶어서-하나의-함수로-만들자\" data-toc-modified-id=\"1~5단계를-한번에-묶어서-하나의-함수로-만들자-3.1.6\"><span class=\"toc-item-num\">3.1.6&nbsp;&nbsp;</span>1~5단계를 한번에 묶어서 하나의 함수로 만들자</a></span></li></ul></li><li><span><a href=\"#단어의-분산-표현\" data-toc-modified-id=\"단어의-분산-표현-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>단어의 분산 표현</a></span></li><li><span><a href=\"#분포-가설\" data-toc-modified-id=\"분포-가설-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>분포 가설</a></span></li><li><span><a href=\"#동시발생-행렬\" data-toc-modified-id=\"동시발생-행렬-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>동시발생 행렬</a></span></li><li><span><a href=\"#벡터-간-유사도\" data-toc-modified-id=\"벡터-간-유사도-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>벡터 간 유사도</a></span></li><li><span><a href=\"#유사-단어의-랭킹-표시\" data-toc-modified-id=\"유사-단어의-랭킹-표시-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>유사 단어의 랭킹 표시</a></span></li></ul></li><li><span><a href=\"#통계-기반-기법-개선하기\" data-toc-modified-id=\"통계-기반-기법-개선하기-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>통계 기반 기법 개선하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#상호-정보량\" data-toc-modified-id=\"상호-정보량-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>상호 정보량</a></span></li><li><span><a href=\"#차원-감소\" data-toc-modified-id=\"차원-감소-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>차원 감소</a></span></li><li><span><a href=\"#SVD에-의한-차원-감소\" data-toc-modified-id=\"SVD에-의한-차원-감소-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>SVD에 의한 차원 감소</a></span></li><li><span><a href=\"#PTB-데이터셋\" data-toc-modified-id=\"PTB-데이터셋-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>PTB 데이터셋</a></span></li><li><span><a href=\"#PTB-데이터셋-평가\" data-toc-modified-id=\"PTB-데이터셋-평가-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>PTB 데이터셋 평가</a></span></li></ul></li><li><span><a href=\"#2장-정리-(p259)\" data-toc-modified-id=\"2장-정리-(p259)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>2장 정리 (p259)</a></span></li><li><span><a href=\"#참고\" data-toc-modified-id=\"참고-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>참고</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서 할 것들을 간단하게 보여주자면 아래와 같다\n",
    "- `자연어 처리(Natural Language Processing)`의 본질적인 목적이 무엇인지 알려주고\n",
    "- Python으로 텍스트를 다루는 연습\n",
    "- 텍스트를 단어 단위로 분할하는 연습\n",
    "- 단어를 단어ID로 변환하는 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:18:12.525285Z",
     "start_time": "2019-10-02T05:18:12.520648Z"
    }
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "\n",
    "mpl.rcParams['font.family'] = 'AppleGothic' # mac에서는 한글이 나오게 하기 위해서\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 자연어 처리란? (p78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`자연어 처리(Natural Language Processing, NLP)`란 자연어를 처리하는 분야이고, 알기 쉽게 설명하자면 인간의 말을 컴퓨터에게 이해시키기 위한 기술이다.\n",
    "\n",
    "![](https://www.kdnuggets.com/wp-content/uploads/nlp-word-cloud.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞으로 이 책에서는 `단어의 의미`를 잘 파악하는 표현방법에 대해서 3가지를 소개할텐데, 간략하게 설명하자면 아래와 같다.\n",
    "\n",
    "1. **시소러스를 활용한 기법** (2장) : 사람의 손으로 만든 유의어 사전을 이용한 방법\n",
    "2. **통계 기반 기법** (2장) : 통계 정보로부터 단어를 표현하는 방법\n",
    "3. **추론 기반 기법** (3장) : `Word2Vec`과 같이 신경망을 활용한 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 시소러스 (p79)\n",
    "\n",
    "- 가장 기본적으로 `단어의 의미`를 나타내는 방법으로는 먼저 사람이 직접 단어의 의미를 정의하는 방식을 생각할 수 있는데, 단어의 의미를 인력을 동원해 정의하려고 하는 것\n",
    "- 시소러스(thesaurus)란 기본적으로 유의어 사전이라고 생각하면 됨, `뜻이 같은 단어(동의어)`나 `뜻이 비슷한 단어(유의어)`가 한 그룹으로 분류  \n",
    "\n",
    "<img src='./img/fig 2-1.png' width=75%>\n",
    "\n",
    "- 단어 사이의 `상위와 하위` 혹은 `전체와 부분` 등 더 세세한 관계까지 정의해둔 경우도 있음\n",
    "\n",
    "<img src='./img/fig 2-2.png' width=75%>\n",
    "\n",
    "- 이처럼 모든 단어에 대한 유의어 집합을 만든 다음, 단어들의 관계를 그래프로 표현하여 단어 사이의 연결을 정의할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet\n",
    "\n",
    "- 자연어 처리 분야에서 가장 유며한 시소러스는 `WordNet`, 이를 사용하면 유의어를 얻거나 단어 네트워크를 이용할 수 있음\n",
    "\n",
    "![](https://i2.wp.com/openscience.com/wp-content/uploads/2016/08/1.png?zoom=2.625&resize=382%2C231&ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시소러스의 문제점\n",
    "\n",
    "하지만 사람이 수작업으로 레이블링하는 방식에는 크나큰 3가지 결점이 존재\n",
    "\n",
    "> 1. 시대 변화에 대응하기 어려움\n",
    "> 2. 사람을 쓰는 비용이 큼\n",
    "> 3. 단어의 미묘한 차이를 표현할 수 없음\n",
    "\n",
    "- 이러한 문제를 해결하고자 `통계 기반 기법`과 `추론 기반 기법`을 알아볼 것\n",
    "- 이 두 기법은 대량의 텍스트 데이터로부터 `단어의 의미`를 `자동으로 추출`할 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 통계 기반 기법 (p82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이썬으로 말뭉치 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T04:55:12.789354Z",
     "start_time": "2019-10-02T04:55:12.786684Z"
    }
   },
   "outputs": [],
   "source": [
    "text = 'You say goodbye and I say hello.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 소문자로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T04:55:27.244481Z",
     "start_time": "2019-10-02T04:55:27.239380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열을 모두 소문자로\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 마침표 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T04:55:48.665022Z",
     "start_time": "2019-10-02T04:55:48.659127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열을 모두 소문자로 만들고 '.'을 ' .'으로 바꾸기\n",
    "text.lower().replace('.',' .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 띄어쓰기 단위로 단어 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T04:56:29.708286Z",
     "start_time": "2019-10-02T04:56:29.702611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 띄어쓰기 단위로 단어를 나누기\n",
    "words = text.lower().replace('.',' .').split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T04:57:46.843167Z",
     "start_time": "2019-10-02T04:57:46.837455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You',\n",
       " ' ',\n",
       " 'say',\n",
       " ' ',\n",
       " 'goodbye',\n",
       " ' ',\n",
       " 'and',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'say',\n",
       " ' ',\n",
       " 'hello',\n",
       " '.',\n",
       " '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식을 통하여 위의 과정을 할 수 있음\n",
    "# 자세한 설명은 정규표현식(제이펍,2016) 참고\n",
    "import re\n",
    "re.split('(\\W+)?',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어를 ID로, ID를 단어로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:02:01.120899Z",
     "start_time": "2019-10-02T05:02:01.114634Z"
    }
   },
   "outputs": [],
   "source": [
    "word_to_id = {} # 단어를 ID로\n",
    "id_to_word = {} # ID를 단어로\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:02:05.881395Z",
     "start_time": "2019-10-02T05:02:05.877393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:02:22.136786Z",
     "start_time": "2019-10-02T05:02:22.132230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:02:09.055122Z",
     "start_time": "2019-10-02T05:02:09.051051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:02:37.820056Z",
     "start_time": "2019-10-02T05:02:37.814422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goodbye'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### corpus 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:06:42.100367Z",
     "start_time": "2019-10-02T05:06:42.091883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1~5단계를 한번에 묶어서 하나의 함수로 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:11:24.404354Z",
     "start_time": "2019-10-02T05:11:24.399589Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # 1단계 : 소문자로 변환하기\n",
    "    text = text.lower()\n",
    "    # 2단계 : 마침표 처리하기\n",
    "    text = text.replace('.',' .')\n",
    "    # 3단계 : 띄어쓰기 단위로 단어 나누기\n",
    "    words = text.split(' ')\n",
    "    # 4단계 : 단어를 ID로, ID를 단어로\n",
    "    word_to_id = {} # 단어를 ID로\n",
    "    id_to_word = {} # ID를 단어로\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "            \n",
    "    # 5단계 : corpus 만들기\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:14:05.624961Z",
     "start_time": "2019-10-02T05:14:05.620801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus     : [0 1 2 3 4 1 5 6]\n",
      "Word to ID : {'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "ID to Word : {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print('{:<10} : {}'.format('Corpus',corpus))\n",
    "print('{:<10} : {}'.format('Word to ID',word_to_id))\n",
    "print('{:<10} : {}'.format('ID to Word',id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:20:17.775354Z",
     "start_time": "2019-10-02T05:20:17.750928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>you</th>\n",
       "      <th>say</th>\n",
       "      <th>goodbye</th>\n",
       "      <th>and</th>\n",
       "      <th>i</th>\n",
       "      <th>hello</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   you  say  goodbye  and  i  hello  .\n",
       "0    0    1        2    3  4      5  6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(word_to_id.values(),index=word_to_id.keys()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T05:20:20.784541Z",
     "start_time": "2019-10-02T05:20:20.768218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>say</td>\n",
       "      <td>goodbye</td>\n",
       "      <td>and</td>\n",
       "      <td>i</td>\n",
       "      <td>hello</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1        2    3  4      5  6\n",
       "0  you  say  goodbye  and  i  hello  ."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(id_to_word.values(),index=id_to_word.keys()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 다음 목표는 말뭉치를 사용해 단어의 의미를 추출하는 것  \n",
    "> 통계 기반 기법을 사용하여 단어를 벡터로 표현할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어의 분산 표현\n",
    "\n",
    "> 자연어 처리 분야에서의 단어의 분산 표현 :  `단어의 의미`를 정확하게 파악할 수 있는 벡터 표현\n",
    "\n",
    "![](https://image.slidesharecdn.com/random-160722004106/95/i-11-638.jpg?cb=1469148206)\n",
    "\n",
    "![](https://t1.daumcdn.net/cfile/tistory/2559F44658EF15AB33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분포 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color='red' size=5>단어의 의미는 <b>주변 단어에 의해 형성</b>된다</font></center>\n",
    "\n",
    "> 단어 자체에는 의미가 없고, 그 단어가 사용되는 **맥락(context)이 의미를 형성한다**는 것\n",
    "\n",
    "<img src='./img/fig 2-3.png' width=75%></img>\n",
    "\n",
    "> 여기서 **맥락(context)**이란 특정 단어를 중심에 둔 그 주변단어를 말하며  \n",
    "주변 단어를 몇 개나 포함할지 결정하는 맥락의 크기를 **윈도우 크기(window size)**라고 함  \n",
    "이 책에서는 이해를 하기 쉽게 좌우 동일하게 고려하지만, 상황에 따라서는 왼쪽만, 혹은 오른쪽만 고려할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동시발생 행렬\n",
    "\n",
    "- 단어를 벡터로 만들어보기 위해선 주변 단어를 세어보는 방법이 가장 자연스럽게 떠오를 것\n",
    "- 다시 말해서, 어떤 단어에 주목했을 때 그 주변에 어떤 단어가 몇 번이나 등장하는지 세어 집계하는 방법\n",
    "- 이를 통계 기반 방법(statistical based method)이라고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T06:05:43.942881Z",
     "start_time": "2019-10-02T06:05:43.936500Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.util import preprocess\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T06:05:47.318645Z",
     "start_time": "2019-10-02T06:05:47.311285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T06:05:51.869667Z",
     "start_time": "2019-10-02T06:05:51.865000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/fig 2-4.png' width=75%>\n",
    "\n",
    "<img src='./img/fig 2-5.png' width=75%>\n",
    "\n",
    "> 여기서 주의해야할 점은 중복되지 않게 구성해야한다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/fig 2-6.png' width=75%>\n",
    "\n",
    "> 이것들은 모든 단어에 대해서 동시발생하는 단어를 표로 정리하면 아래와 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=5> 동시발생 행렬<br>(co-occurrence matrix)</font></center>\n",
    "<img src='./img/fig 2-7.png' width=75%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T06:15:44.517107Z",
     "start_time": "2019-10-02T06:15:44.511219Z"
    }
   },
   "outputs": [],
   "source": [
    "# 말뭉치로부터 동시발생 행렬을 만들어주는 함수\n",
    "def create_co_matrix(corpus, vocab_size,window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size,vocab_size),dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx - 1\n",
    "            right_idx = idx + 1\n",
    "            \n",
    "            # 왼쪽 끝에 있는지 확인\n",
    "            if left_idx >= 0 :\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id,left_word_id] += 1\n",
    "                \n",
    "            # 오른쪽 끝에 있는지 확인\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id,right_word_id] += 1\n",
    "                \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T06:19:31.607083Z",
     "start_time": "2019-10-02T06:19:31.594161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>you</th>\n",
       "      <th>say</th>\n",
       "      <th>goodbye</th>\n",
       "      <th>and</th>\n",
       "      <th>i</th>\n",
       "      <th>hello</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodbye</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hello</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         you  say  goodbye  and  i  hello  .\n",
       "you        0    1        0    0  0      0  0\n",
       "say        1    0        1    0  1      1  0\n",
       "goodbye    0    1        0    1  0      0  0\n",
       "and        0    0        1    0  1      0  0\n",
       "i          0    1        0    1  0      0  0\n",
       "hello      0    1        0    0  0      0  1\n",
       ".          0    0        0    0  0      1  0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common.utils import \n",
    "word_list = list(word_to_id.keys())\n",
    "vocab_size = len(word_to_id)\n",
    "pd.DataFrame(create_co_matrix(corpus,vocab_size),index=word_list,columns=word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 간 유사도\n",
    "\n",
    "- 단어가 얼마나 비슷한지 유사도 순으로 출력하는 함수를 만들어봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similiar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사 단어의 랭킹 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 통계 기반 기법 개선하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상호 정보량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD에 의한 차원 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTB 데이터셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2장 정리 (p259)\n",
    "\n",
    "> 참고 : [WegraLee GitHub](https://github.com/WegraLee/deep-learning-from-scratch-2/blob/master/ch02/README.md)\n",
    "\n",
    "- 추론 기반 기법은 추측하는 것이 목적임, 이를 통해서 단어의 분산 표현을 얻을 수 있음\n",
    "- `Word2Vec`은 **추론 기반 기법**이며, 단순한 2층 신경망\n",
    "- Word2Vec은 `skip-gram`모델과 `CBOW`모델을 제공\n",
    "- CBOW 모델은 여러 단어(맥락)으로부터 하나의 단어(타킷)를 추측\n",
    "- skip-gram 모델은 하나의 단어(타킷)으로부터 다수의 단어(맥락)을 추측\n",
    "- `Word2Vec`의 가중치를 다시 학습할 수 있으므로, 단어의 분산 표현 갱신이나 새로운 단어 추가를 효율적으로 수행할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 참고\n",
    "- 밑바닥부터 시작하는 딥러닝 GitHub : https://github.com/WegraLee/deep-learning-from-scratch-2  \n",
    "- Mathjax 웹 수식 : https://www.codecogs.com/latex/eqneditor.php / http://detexify.kirelabs.org/classify.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "2장 자연어와 단어의 분산 표현",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "335.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
